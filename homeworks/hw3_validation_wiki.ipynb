{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 3 \n",
    "\n",
    "You will have 2 datasets to work on. \n",
    "#### You have to answer questions in this [form](https://goo.gl/forms/5gfxvKZxpoydoeOB2) and provide your code\n",
    "\n",
    "### 1. Wikipedia Web Traffic Time Series\n",
    "\n",
    "Data from [Kaggle competition](https://www.kaggle.com/c/web-traffic-time-series-forecasting)* )\n",
    "\n",
    "*wikipedia_train3* - train data *wikipedia_test3* - test data created by us from original train data . For more information about dataset, please visit Homework1 assignment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wikipedia page views (SMAPE metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../data/wikipedia3/wikipedia_train3.csv\", parse_dates = ['date'])\n",
    "test = pd.read_csv(\"../data/wikipedia3/wikipedia_test3.csv\", parse_dates = ['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Page</th>\n",
       "      <th>date</th>\n",
       "      <th>Visits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>774311</th>\n",
       "      <td>Wikipedia_de.wikipedia.org_desktop_all-agents</td>\n",
       "      <td>2016-03-06</td>\n",
       "      <td>5088.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019461</th>\n",
       "      <td>Lyle_and_Erik_Menendez_en.wikipedia.org_all-ac...</td>\n",
       "      <td>2016-03-27</td>\n",
       "      <td>2665.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1271216</th>\n",
       "      <td>Illuminati_en.wikipedia.org_mobile-web_all-agents</td>\n",
       "      <td>2016-04-17</td>\n",
       "      <td>8448.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      Page       date  Visits\n",
       "774311       Wikipedia_de.wikipedia.org_desktop_all-agents 2016-03-06  5088.0\n",
       "1019461  Lyle_and_Erik_Menendez_en.wikipedia.org_all-ac... 2016-03-27  2665.0\n",
       "1271216  Illuminati_en.wikipedia.org_mobile-web_all-agents 2016-04-17  8448.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.** Take a look carefuly at train and test dataset. Note for you what is the difference in them and how they are dependent. **For _only_ train** create a holdout validation using any type of split you think is useful here. What is the split type you are using? Answer in google forms\n",
    "\n",
    "**2.** Write a code to compare the score of your validation and test set. For scoring, use metric SMAPE (code is in lecture). For prediction use 15 previous days median. In the google form write your validation score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SMAPE METRIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SMAPE(forecast, actual):\n",
    "    if forecast.size != actual.size:\n",
    "        raise ValueError('Forecast and actual data have different dimensions: F.size = {}, A.size = {}'.format(forecast.size, actual.size))\n",
    "    \n",
    "    pure_forecast = forecast.fillna(0)\n",
    "    \n",
    "    error = (pure_forecast - actual).abs()\n",
    "    avarage = (pure_forecast.abs() + actual.abs())/2\n",
    "    smape_series = error/avarage\n",
    "    \n",
    "    smape_series.fillna(0, inplace = True)\n",
    "    return 100*smape_series.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: From 2016-01-01 to 2016-08-31\n",
      "TEST: From 2016-09-10 to 2016-11-10\n"
     ]
    }
   ],
   "source": [
    "min_train_date = train['date'].min()\n",
    "max_train_date = train['date'].max()\n",
    "\n",
    "min_test_date = test['date'].min()\n",
    "max_test_date = test['date'].max()\n",
    "\n",
    "print('TRAIN: From {} to {}'.format(min_train_date.date(), max_train_date.date()))\n",
    "print('TEST: From {} to {}'.format(min_test_date.date(), max_test_date.date()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Holdout validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we use prediction based on median of last N days and our test set consists of data within a period of next two monthes It would be reasonable to split data into 4 parts:\n",
    "\n",
    "+ holdout with size of two next months\n",
    "+ gap of one month and 10 days to drop\n",
    "+ train set with N last days\n",
    "+ other data to drop "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into holdout and train only:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_N_days = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_date = max_train_date - relativedelta(months = 2)\n",
    "train_holdout_gap = relativedelta(months = 1, days = 10)\n",
    "train_date = holdout_date - train_holdout_gap - relativedelta(days = last_N_days)\n",
    "\n",
    "holdout_indices = train.date >= holdout_date\n",
    "train_inices = (train_date <= train.date) & (train.date < holdout_date)\n",
    "\n",
    "holdout = train[holdout_indices]\n",
    "train_pure = train[train_inices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(train, test):\n",
    "    test_prediction = test.merge(\n",
    "        train.groupby(['Page']).median().reset_index().rename({'Visits': 'prediction'}, axis = 'columns'), \n",
    "        on = ['Page'], how = 'left')\n",
    "    \n",
    "    return test_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction_SMAPE(train, test):\n",
    "    test_prediction = get_prediction(train, test)\n",
    "    return SMAPE(test_prediction['prediction'], test_prediction['Visits'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMAPE for holdout data over the last 2 months and train data over preceding 15 days: 44.934277560873\n"
     ]
    }
   ],
   "source": [
    "holdout_smape = get_prediction_SMAPE(train_pure, holdout)\n",
    "print('SMAPE for holdout data over the last 2 months and train data over preceding 15 days: {}'.format(holdout_smape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_date = max_train_date - relativedelta(days = 15)\n",
    "train_inices = train_date <= train.date\n",
    "train_pure = train[train_inices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMAPE for holdout data over the next 2 months and train data over last 15 days: 40.207352322566344\n"
     ]
    }
   ],
   "source": [
    "test_smape = get_prediction_SMAPE(train_pure, test)\n",
    "print('SMAPE for holdout data over the next 2 months and train data over last 15 days: {}'.format(test_smape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**3.** Perform K-fold validation using your type of split. Run GridSearch with any classificator you like and set of parameters to optimize, providing it with your custom validation.  Compare the score of your validation and test set. For scoring, again, use metrics SMAPE. In the google form write your scores on validation and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose the best 'last N' parametr  using floating window, 5 folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_window = 2 #months\n",
    "holdout_window = 2 #months\n",
    "\n",
    "folds_number = 5\n",
    "folds_period = relativedelta(max_train_date, min_train_date) - relativedelta(months = train_window + holdout_window) - train_holdout_gap\n",
    "window_step = (folds_period.days + folds_period.months * 30) // folds_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_validation(df, start_date):\n",
    "    holdout_start = start_date + relativedelta(months = train_window) + train_holdout_gap\n",
    "    holdout_end = holdout_start + relativedelta(months = holdout_window)\n",
    "    \n",
    "    if holdout_end > max_train_date:\n",
    "        raise ValueError('holdout_window + train_window + start_date should be < than max_train_date. We want to use floating window with train size {} months and holdout size {} months.'.format(train_window, holdout_window))\n",
    " \n",
    "    train_indices = (df.date >= start_date) & (df.date < holdout_start)\n",
    "    holdout_indices = (df.date >= holdout_start) & (df.date < holdout_end)\n",
    "\n",
    "    return train_indices, holdout_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_start_dates = [min_train_date + relativedelta(days = window_step * i) for i in range(folds_number)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation from 2016-01-01 to 2016-08-31:\n",
      "0.Train: from 2016-01-01 to 2016-03-01,\n",
      "  Holdout: from 2016-04-11 to 2016-06-11\n",
      "1.Train: from 2016-01-17 to 2016-03-17,\n",
      "  Holdout: from 2016-04-27 to 2016-06-27\n",
      "2.Train: from 2016-02-02 to 2016-04-02,\n",
      "  Holdout: from 2016-05-12 to 2016-07-12\n",
      "3.Train: from 2016-02-18 to 2016-04-18,\n",
      "  Holdout: from 2016-05-28 to 2016-07-28\n",
      "4.Train: from 2016-03-05 to 2016-05-05,\n",
      "  Holdout: from 2016-06-15 to 2016-08-15\n"
     ]
    }
   ],
   "source": [
    "print('Cross validation from {} to {}:'.format(min_train_date.date(), max_train_date.date()))\n",
    "for i, train_start in enumerate(train_start_dates):\n",
    "    train_end = train_start + relativedelta(months = train_window)\n",
    "    holdout_start = train_end + train_holdout_gap\n",
    "    holdout_end = holdout_start + relativedelta(months = holdout_window)\n",
    "    print('{}.Train: from {} to {},'.format(i, train_start.date(), train_end.date()))\n",
    "    print('  Holdout: from {} to {}'.format(holdout_start.date(), holdout_end.date()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "CVIterator = []\n",
    "for i in train_start_dates:\n",
    "    train_indices, holdout_indices = create_validation(train, i)\n",
    "    CVIterator.append((train_indices, holdout_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean SMAPE for last 1 days: 42.83186996075777\n",
      "Mean SMAPE for last 2 days: 41.88165552374041\n",
      "Mean SMAPE for last 3 days: 41.575264213769145\n",
      "Mean SMAPE for last 5 days: 40.8600628446685\n",
      "Mean SMAPE for last 8 days: 41.50156879388365\n",
      "Mean SMAPE for last 13 days: 40.985370072241366\n",
      "Mean SMAPE for last 21 days: 41.75113354602299\n",
      "Mean SMAPE for last 34 days: 42.73413688065837\n",
      "Mean SMAPE for last 55 days: 44.19190516427825\n"
     ]
    }
   ],
   "source": [
    "test_last_N_days = [1, 2, 3, 5, 8, 13, 21, 34, 55]\n",
    "\n",
    "result = {}\n",
    "for i, N in enumerate(test_last_N_days):\n",
    "    smapes = []\n",
    "    for train_indices, holdout_indices in CVIterator:\n",
    "        current_train = train[train_indices]\n",
    "        current_holdout = train[holdout_indices]\n",
    "        \n",
    "        actual_N_train_start = current_train.date.max() - relativedelta(days = N)\n",
    "        actual_N_train = current_train[current_train.date >= actual_N_train_start]\n",
    "        \n",
    "        current_smape = get_prediction_SMAPE(actual_N_train, current_holdout)\n",
    "        smapes.append(current_smape)\n",
    "    \n",
    "    smapes_series = pd.Series(smapes)\n",
    "    print('Mean SMAPE for last {} days: {}'.format(N, smapes_series.mean()))\n",
    "    result[N] = smapes_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get the best SMAPE using 5 last days for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMAPE for test data for the next 2 months using train data over the last 5 days: 40.14220878443605\n"
     ]
    }
   ],
   "source": [
    "last_N_days = 5\n",
    "last_N_days_train = train[train.date >= max_train_date - relativedelta(days = last_N_days)]\n",
    "test_smape = get_prediction_SMAPE(last_N_days_train, test)\n",
    "print('SMAPE for test data for the next 2 months using train data over the last {} days: {}'.format(last_N_days, test_smape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see we got even less SMAPE using 10 last days to predict visits for the next 2 months. We get this hyperparameter on cross validation, so it more robust to overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Use linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_language(page):\n",
    "    res = re.search('[a-z][a-z].wikipedia.org', page)\n",
    "    if res:\n",
    "        return res.group(0)[0:2]\n",
    "    return 'na'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(x):\n",
    "    x['lang'] = get_language(x['Page'])\n",
    "    x['isweekend'] = 1 if x.date.weekday() >= 5 else 0\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_trasnformed = train.apply(transform, axis = 'columns').drop(['date', 'Page', 'Visits'], axis = 'columns')\n",
    "\n",
    "X_train = pd.get_dummies(X_train_trasnformed)\n",
    "y_train = train['Visits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_trasnformed = test.apply(transform, axis = 'columns').drop(['date', 'Page', 'Visits'], axis = 'columns')\n",
    "\n",
    "X_test = pd.get_dummies(X_test_trasnformed)\n",
    "y_test = test['Visits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isweekend</th>\n",
       "      <th>lang_de</th>\n",
       "      <th>lang_en</th>\n",
       "      <th>lang_es</th>\n",
       "      <th>lang_fr</th>\n",
       "      <th>lang_ja</th>\n",
       "      <th>lang_na</th>\n",
       "      <th>lang_ru</th>\n",
       "      <th>lang_zh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2087522</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2443888</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2722790</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2729837</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044285</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         isweekend  lang_de  lang_en  lang_es  lang_fr  lang_ja  lang_na  \\\n",
       "2087522          1        0        1        0        0        0        0   \n",
       "2443888          0        0        0        1        0        0        0   \n",
       "2722790          0        0        1        0        0        0        0   \n",
       "2729837          0        0        1        0        0        0        0   \n",
       "1044285          0        0        1        0        0        0        0   \n",
       "\n",
       "         lang_ru  lang_zh  \n",
       "2087522        0        0  \n",
       "2443888        0        0  \n",
       "2722790        0        0  \n",
       "2729837        0        0  \n",
       "1044285        0        0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_bool_iterator(train_bool_indices, holdout_bool_indices):\n",
    "    new_train_indices = train_bool_indices[train_bool_indices].index\n",
    "    new_holdout_indices = holdout_bool_indices[holdout_bool_indices].index\n",
    "\n",
    "    return new_train_indices, new_holdout_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_CVIterator = []\n",
    "\n",
    "for train_indices, holdout_indices in CVIterator:\n",
    "    new_train_indices, new_holdout_indices = map_bool_iterator(train_indices, holdout_indices)\n",
    "    index_CVIterator.append((new_train_indices, new_holdout_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scorer_function(y_true, y_pred):\n",
    "    pred = pd.Series(y_pred).reset_index(drop = True)\n",
    "    act = pd.Series(y_true).reset_index(drop = True)\n",
    "    smape = SMAPE(pred, act)\n",
    "    return smape\n",
    "\n",
    "scorer = make_scorer(scorer_function, greater_is_better = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=[(Int64Index([      0,       1,       2,       3,       4,       5,       6,\n",
       "                  7,       8,       9,\n",
       "            ...\n",
       "            1193305, 1193306, 1193307, 1193308, 1193309, 1193310, 1193311,\n",
       "            1193312, 1193313, 1193314],\n",
       "           dtype='int64', length=1193315), Int64In...2682000, 2682001,\n",
       "            2682002, 2682003, 2682004],\n",
       "           dtype='int64', length=720715))],\n",
       "       error_score='raise',\n",
       "       estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001),\n",
       "       fit_params=None, iid=True, n_jobs=4,\n",
       "       param_grid={'alpha': [0.1, 1, 3, 5, 10, 50]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=make_scorer(scorer_function, greater_is_better=False),\n",
       "       verbose=0)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor = Ridge()\n",
    "\n",
    "grid = {\n",
    "    'alpha': [0.1, 1, 3, 5, 10, 50]\n",
    "}\n",
    "grid_search = GridSearchCV(\n",
    "    regressor, \n",
    "    param_grid = grid, \n",
    "    cv = index_CVIterator, \n",
    "    scoring = scorer,\n",
    "    n_jobs = os.cpu_count()//2,\n",
    "    return_train_score = True\n",
    ")\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = pd.Series(grid_search.best_estimator_.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMAPE for test data for the next 2 months using Ridge regression: 112.22684934380054\n"
     ]
    }
   ],
   "source": [
    "test_regression_smape = SMAPE(prediction, y_test)\n",
    "print('SMAPE for test data for the next 2 months using Ridge regression: {}'.format(test_regression_smape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMAPE for test data for the next 2 months using Linear regression: 112.22621967099843\n"
     ]
    }
   ],
   "source": [
    "linear_regressor = LinearRegression()\n",
    "linear_regressor.fit(X_train, y_train)\n",
    "\n",
    "prediction = pd.Series(linear_regressor.predict(X_test))\n",
    "\n",
    "test_regression_smape = SMAPE(prediction, y_test)\n",
    "print('SMAPE for test data for the next 2 months using Linear regression: {}'.format(test_regression_smape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear models are poor here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
